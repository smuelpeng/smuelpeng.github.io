---
title: 关于caffe
date: 2018-01-13 21:56:06
tags:
---
##caffe是什么
caffe是一个C++的函数库，里面有很多关于CNN的函数，也有基于C++库函数的其他语言接口封装实现。
caffe极大促进了神经网络的广泛发展，即使并不理解C++和CNN的同学，在通过对于caffe的不断学习也可以获得很大的提升。
研究生期间对于caffe的不断使用和理解的过程中，深感其影响甚大，随着tensorflow或者pytorch的逐渐普及，caffe渐渐会退出历史舞台，但其设计思路、构建工具和传播方式对以后的软件发展都有着很大的意义。
## 正文
### 1.设计思路：
caffe的关键的设计思路可以分为这样几层：
#### 1.1 底层：内存处理与内存计算 blob 
程序的本质是对内存的操作，能够快速有效地处理数据便是数据结构的存在意义。
caffe的底层内存处理设计是一个状态机，使用流程图说明则一目了然:
![blob_machine](/images/blob_machine.png)	
这样的设计有几个特点：
+ 符合不过过度设计的原则，即运行时不会用到的内存，在设计时也不必分配，具体体现在如果整个过程种都没有使用cpu_data()函数，那么就不会分配内存。
+ 频繁使用的内存，不会重复申请和释放，具体体现在即使当前blob的当前占用内存和实际需要的内存不匹配时，只会在不够时重新分配，如果比实际需求的多，那么不会做改变。

同样会有几个现象：
+ caffe的内存申请只会变大，不会变小
例如人脸检测中，输入图片大小不同，那么合理的内存是随着图片大小的尺寸而改变的，但在为较大尺寸图片分配了较大内存之后，caffe的内存分配机制并不会为接下来的小尺寸图片减少使用的内存，这就会造成很大程度上的内存浪费，而在一些误操作如输入了尺寸很大的图片的时候，就会造成out of memory。
+
caffe的内存分配是固定的，所以caffe是不支持多线程运行的；例如在模型预测的时候，使用同一个Net多线程做前馈，那么多半会出错。

#### 1.2 中层：layer的构建与组合
layer其实就是内存的计算和整理操作，往往遵循着神经元结构的设计法则，即一个或者多个参数相乘计算层+激活函数层，算是完成一个神经元结构操作。
和通信中的信号调制与解调相互对应的话，layer就像信号传递系统种的各种模块，那么可以大胆类比每个layer是将信号对于频域的搬运和增强，激活函数可以看作对不同频段上信号的截断。
caffe中的layer设计比较经典，基类layer，要求规定好输入、输出blob，抽象的前馈函数forward和后馈函数backward。前馈正向计算输出blob，后馈更新输入blob的diff，用于修正layer的自身参数。
layer可以是非常复杂操作，比如卷积层就有很多种实现方式，其操作结果都一样，实现方式则可以通过im2col，MEC，winogard等算法进行加速。

#### 1.3 高层：网络的应用
![layers](/images/layers_caffe)

### 2.构建工具：
caffe的构建很多时候都会困扰着初学者和开发者，

对于初学者来说，问题在于caffe的依赖库很多，而且依赖库自身的版本也很多，稍有不慎就会花很多的时间去调整环境，甚至一同操作之后还要落得个重装系统的下场。

对于开发者而言，caffe就是一个C++库，处理依赖方面和其他的C++函数库并无区别，但存在训练速度到交付前馈速度冗余去除问题。

caffe的构建涉及从基础编译，到不同平台的优化版本caffe的编译，再到将caffe作为软件系统的一部分。

caffe的基础编译操作：
这里指的基础编译不是官网里的一番sudo或者apt-get。
而是需要在各个操作的系统和硬件环境中编译出caffe。因此要考虑的事情就变得很多了。

首先是操作系统，熟知且有使用价值的操作系统就只有Linux和Windows，程序代码的功能设计并不应当受到操作系统的限制，
跨系统C++库构建可以借助于CMake等框架进行编译，但是要注意这两种操作系统之间构建C++程序的方式有所不同
+ **不同系统之基础库的区别，如time.h-gettimeofday();Windows.h->pause()等**
+ **MSVC和Linux G++对动态库和静态库编译选项不同，如Windows的Addition Path和Linux的LIBRARY_PATH**
+ **运行时加载symbol的路径不同如windows-system32;$PATH和Linux-/lib;$LD_LIBRARY_PATH等**

其次是CPU的兼容，由于CNN是计算依赖型的任务，需要使用到如openblas，MKL等线性代数加速库，
而这些加速库也依赖于CPU支持的指令集，如SSE，AVX，AVX2等超线程指令集，加速库在编译时就确定使用哪些指令集，
但是如果实际使用中遇到了和编译时不同的cpu平台，那么就可能会出现一定的问题。

GPU同样存在类似的问题，Cudnn是很关键的显卡CNN加速库，Cudnn的架构依赖也就决定了对GPU的依赖。

依赖库的版本同样是一个很繁琐的问题，如果编译或者运行环境中，存在不同版本的protobuf，那么很大概率会发生，
无法解析prototxt的事情发生。如果存在不同版本的glog和gflags，那么可能存在glog无法编译的现象。

编译时软连接依赖，运行时却需要带版本号的依赖库，比如很多时候会发生这样的情况：编译的时候使用-lxxx,
需要将libxxx.so加入编译路径，但运行时会提示xxx.bin 需要libxxx.so.*.*，简单的将libxxx.so拷贝就可以，但是这真的很烦


解决这些问题其实并不难，贵在高效简洁处理。
第一步是编译阶段
+ 通过代码中设置definition，如-DUSE_xxx等来选择适合不同系统的代码来使用。
+ 了解第三方库的使用，[openblas的编译选项](https://my.oschina.net/xianyi/blog/101897)


第二步是链接，
+ 不同cpp生成的object可以编到ELF文件中去，
+ Cmake种使用link_directories来包含需要连接的第三方库

第三步是链接到可执行文件

第四步是运行时加载

对于小成本的使用者，非常希望训练

需要便捷开发者来说,git+blade的方式一定是具有诱惑力的。

